{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sklearn 0.19\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, svm, tree, preprocessing, metrics\n",
    "# because cv is depressed since 1.8, do below\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "\n",
    "import sklearn.ensemble as ske\n",
    "import tensorflow as tf\n",
    "#from tensorflow.contrib.learn import skflow\n",
    "import tensorflow.contrib.learn as skflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load, play and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('./train.csv')\n",
    "raw_df.columns = map(str.lower, raw_df.columns)\n",
    "titanic_df = raw_df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']].copy()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>female</th>\n",
       "      <td>0.968085</td>\n",
       "      <td>34.611765</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>106.125798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.368852</td>\n",
       "      <td>41.281386</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>67.226127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>female</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>28.722973</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>21.970121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.157407</td>\n",
       "      <td>30.740707</td>\n",
       "      <td>0.342593</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>19.741782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>female</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>16.118810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.135447</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>0.498559</td>\n",
       "      <td>0.224784</td>\n",
       "      <td>12.661633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived        age     sibsp     parch        fare\n",
       "pclass sex                                                        \n",
       "1      female  0.968085  34.611765  0.553191  0.457447  106.125798\n",
       "       male    0.368852  41.281386  0.311475  0.278689   67.226127\n",
       "2      female  0.921053  28.722973  0.486842  0.605263   21.970121\n",
       "       male    0.157407  30.740707  0.342593  0.222222   19.741782\n",
       "3      female  0.500000  21.750000  0.895833  0.798611   16.118810\n",
       "       male    0.135447  26.507589  0.498559  0.224784   12.661633"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sex_grouping = titanic_df.groupby(['pclass','sex']).mean()\n",
    "class_sex_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fe6e638a20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAE3CAYAAABRmAGSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fe6e5fd6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_sex_grouping['survived'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# titanic_df['sex'].unique()\n",
    "# sexes = sorted(titatitanic_df['sex'].unique()\n",
    "# sexes = sorted(titanic_df['sex'].unique())\n",
    "# genders_mapping = dict(zip(sexes, range(0, len(sexes) + 1)))\n",
    "# titanic_df['sex_mod'] = titanic_df['sex'].map(genders_mapping).astype(int)\n",
    "\n",
    "# titanic_df['embarked'].fillna('-', inplace=True)\n",
    "# embarked_locs = sorted(titanic_df['embarked'].unique())\n",
    "# embarked_locs_mapping = dict(zip(embarked_locs, range(0, len(embarked_locs) + 1)))\n",
    "# embarked_locs_mapping\n",
    "# titanic_df['embarked_Mod'] = titanic_df['embarked'].map(embarked_locs_mapping).astype(int)\n",
    "\n",
    "# titanic_df['age_mod'] = titanic_df['age']\n",
    "# titanic_df['age_mod'] = titanic_df['age_mod'].groupby([titanic_df['sex_mod'], titanic_df['pclass']]).apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# titanic_df = titanic_df.drop(['age','sex','embarked'], axis=1)\n",
    "\n",
    "# titanic_df.count()nic_df['sex'].unique())\n",
    "# genders_mapping = dict(zip(sexes, range(0, len(sexes) + 1)))\n",
    "# titanic_df['sex_mod'] = titanic_df['sex'].map(genders_mapping).astype(int)\n",
    "\n",
    "# titanic_df['embarked'].fillna('-', inplace=True)\n",
    "# embarked_locs = sorted(titanic_df['embarked'].unique())\n",
    "# embarked_locs_mapping = dict(zip(embarked_locs, range(0, len(embarked_locs) + 1)))\n",
    "# embarked_locs_mapping\n",
    "# titanic_df['embarked_Mod'] = titanic_df['embarked'].map(embarked_locs_mapping).astype(int)\n",
    "\n",
    "# titanic_df['age_mod'] = titanic_df['age']\n",
    "# titanic_df['age_mod'] = titanic_df['age_mod'].groupby([titanic_df['sex_mod'], titanic_df['pclass']]).apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# titanic_df = titanic_df.drop(['age','sex','embarked'], axis=1)\n",
    "\n",
    "# titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_titanic_df(df):\n",
    "    processed_df = df.copy()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    processed_df.sex = le.fit_transform(processed_df.sex)\n",
    "    processed_df.embarked = processed_df.embarked.fillna('-')\n",
    "    # inplace..\n",
    "    processed_df.embarked = le.fit_transform(processed_df.embarked)\n",
    "    processed_df['age'] = titanic_df['age'].groupby([titanic_df['sex'], titanic_df['pclass']]).apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    processed_df = processed_df.drop(['name','ticket', \"cabin\"],axis=1)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passengerid  survived  pclass  sex   age  sibsp  parch      fare  \\\n",
       "0              1         0       3    1  22.0      1      0    7.2500   \n",
       "1              2         1       1    0  38.0      1      0   71.2833   \n",
       "2              3         1       3    0  26.0      0      0    7.9250   \n",
       "3              4         1       1    0  35.0      1      0   53.1000   \n",
       "4              5         0       3    1  35.0      0      0    8.0500   \n",
       "5              6         0       3    1  25.0      0      0    8.4583   \n",
       "6              7         0       1    1  54.0      0      0   51.8625   \n",
       "7              8         0       3    1   2.0      3      1   21.0750   \n",
       "8              9         1       3    0  27.0      0      2   11.1333   \n",
       "9             10         1       2    0  14.0      1      0   30.0708   \n",
       "10            11         1       3    0   4.0      1      1   16.7000   \n",
       "11            12         1       1    0  58.0      0      0   26.5500   \n",
       "12            13         0       3    1  20.0      0      0    8.0500   \n",
       "13            14         0       3    1  39.0      1      5   31.2750   \n",
       "14            15         0       3    0  14.0      0      0    7.8542   \n",
       "15            16         1       2    0  55.0      0      0   16.0000   \n",
       "16            17         0       3    1   2.0      4      1   29.1250   \n",
       "17            18         1       2    1  30.0      0      0   13.0000   \n",
       "18            19         0       3    0  31.0      1      0   18.0000   \n",
       "19            20         1       3    0  21.5      0      0    7.2250   \n",
       "20            21         0       2    1  35.0      0      0   26.0000   \n",
       "21            22         1       2    1  34.0      0      0   13.0000   \n",
       "22            23         1       3    0  15.0      0      0    8.0292   \n",
       "23            24         1       1    1  28.0      0      0   35.5000   \n",
       "24            25         0       3    0   8.0      3      1   21.0750   \n",
       "25            26         1       3    0  38.0      1      5   31.3875   \n",
       "26            27         0       3    1  25.0      0      0    7.2250   \n",
       "27            28         0       1    1  19.0      3      2  263.0000   \n",
       "28            29         1       3    0  21.5      0      0    7.8792   \n",
       "29            30         0       3    1  25.0      0      0    7.8958   \n",
       "..           ...       ...     ...  ...   ...    ...    ...       ...   \n",
       "861          862         0       2    1  21.0      1      0   11.5000   \n",
       "862          863         1       1    0  48.0      0      0   25.9292   \n",
       "863          864         0       3    0  21.5      8      2   69.5500   \n",
       "864          865         0       2    1  24.0      0      0   13.0000   \n",
       "865          866         1       2    0  42.0      0      0   13.0000   \n",
       "866          867         1       2    0  27.0      1      0   13.8583   \n",
       "867          868         0       1    1  31.0      0      0   50.4958   \n",
       "868          869         0       3    1  25.0      0      0    9.5000   \n",
       "869          870         1       3    1   4.0      1      1   11.1333   \n",
       "870          871         0       3    1  26.0      0      0    7.8958   \n",
       "871          872         1       1    0  47.0      1      1   52.5542   \n",
       "872          873         0       1    1  33.0      0      0    5.0000   \n",
       "873          874         0       3    1  47.0      0      0    9.0000   \n",
       "874          875         1       2    0  28.0      1      0   24.0000   \n",
       "875          876         1       3    0  15.0      0      0    7.2250   \n",
       "876          877         0       3    1  20.0      0      0    9.8458   \n",
       "877          878         0       3    1  19.0      0      0    7.8958   \n",
       "878          879         0       3    1  25.0      0      0    7.8958   \n",
       "879          880         1       1    0  56.0      0      1   83.1583   \n",
       "880          881         1       2    0  25.0      0      1   26.0000   \n",
       "881          882         0       3    1  33.0      0      0    7.8958   \n",
       "882          883         0       3    0  22.0      0      0   10.5167   \n",
       "883          884         0       2    1  28.0      0      0   10.5000   \n",
       "884          885         0       3    1  25.0      0      0    7.0500   \n",
       "885          886         0       3    0  39.0      0      5   29.1250   \n",
       "886          887         0       2    1  27.0      0      0   13.0000   \n",
       "887          888         1       1    0  19.0      0      0   30.0000   \n",
       "888          889         0       3    0  21.5      1      2   23.4500   \n",
       "889          890         1       1    1  26.0      0      0   30.0000   \n",
       "890          891         0       3    1  32.0      0      0    7.7500   \n",
       "\n",
       "     embarked  \n",
       "0           3  \n",
       "1           1  \n",
       "2           3  \n",
       "3           3  \n",
       "4           3  \n",
       "5           2  \n",
       "6           3  \n",
       "7           3  \n",
       "8           3  \n",
       "9           1  \n",
       "10          3  \n",
       "11          3  \n",
       "12          3  \n",
       "13          3  \n",
       "14          3  \n",
       "15          3  \n",
       "16          2  \n",
       "17          3  \n",
       "18          3  \n",
       "19          1  \n",
       "20          3  \n",
       "21          3  \n",
       "22          2  \n",
       "23          3  \n",
       "24          3  \n",
       "25          3  \n",
       "26          1  \n",
       "27          3  \n",
       "28          2  \n",
       "29          3  \n",
       "..        ...  \n",
       "861         3  \n",
       "862         3  \n",
       "863         3  \n",
       "864         3  \n",
       "865         3  \n",
       "866         1  \n",
       "867         3  \n",
       "868         3  \n",
       "869         3  \n",
       "870         3  \n",
       "871         3  \n",
       "872         3  \n",
       "873         3  \n",
       "874         1  \n",
       "875         1  \n",
       "876         3  \n",
       "877         3  \n",
       "878         3  \n",
       "879         1  \n",
       "880         3  \n",
       "881         3  \n",
       "882         3  \n",
       "883         3  \n",
       "884         3  \n",
       "885         2  \n",
       "886         3  \n",
       "887         3  \n",
       "888         3  \n",
       "889         1  \n",
       "890         2  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = preprocess_titanic_df(raw_df)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = processed_df.drop(['survived'], axis=1).values\n",
    "y = processed_df['survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988826815642458"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=10)\n",
    "clf_dt.fit(features, label)\n",
    "clf_dt.score(features_test, label_test)\n",
    "# pd.DataFrame(data=X_train)\n",
    "# org = pd.DataFrame(data=y_train) \n",
    "# se = pd.Series(predicted)\n",
    "# org['predicted'] = se.values\n",
    "# org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shuffle_validator = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "def test_classifier(clf):\n",
    "    scores = cross_val_score(clf, X, y, cv=shuffle_validator)\n",
    "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7922 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "test_classifier(clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Other simple Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The **“Random Forest”** classification algorithm will create a multitude of (generally very poor) trees for the data set using different random subsets of the input variables, and will return whichever prediction was returned by the most trees. This helps to avoid “overfitting”, a problem that occurs when a model is so tightly fitted to arbitrary correlations in the training data that it performs poorly on test data.\n",
    "\n",
    "The **“Gradient Boosting”** classifier will generate many weak, shallow prediction trees and will combine, or “boost”, them into a strong model. This model performs very well on our data set, but has the drawback of being relatively slow and difficult to optimize, as the model construction happens sequentially so it cannot be parallelized.\n",
    "\n",
    "A **“Voting”** classifier can be used to apply multiple conceptually divergent classification models to the same data set and will return the majority vote from all of the classifiers. For instance, if the gradient boosting classifier predicts that a passenger will not survive, but the decision tree and random forest classifiers predict that they will live, the voting classifier will chose the latter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8274 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "test_classifier(clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8318 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8332 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "eclf = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb)])\n",
    "test_classifier(eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Neural Networks - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FE6EABDC88>, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_environment': 'local', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_task_id': 0, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_task_type': None, '_tf_random_seed': None, '_evaluation_master': ''}\n",
      "WARNING:tensorflow:From <ipython-input-16-4828b6551cd4>:11: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-16-4828b6551cd4>:11: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:247: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 201 into ./titanic_DNN_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.626438, step = 201\n",
      "INFO:tensorflow:global_step/sec: 303.603\n",
      "INFO:tensorflow:loss = 0.617631, step = 301\n",
      "INFO:tensorflow:Saving checkpoints for 400 into ./titanic_DNN_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.608085.\n",
      "WARNING:tensorflow:From <ipython-input-16-4828b6551cd4>:12: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-16-4828b6551cd4>:12: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-03-28-08:05:47\n",
      "INFO:tensorflow:Finished evaluation at 2017-03-28-08:05:48\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.731844, accuracy/baseline_label_mean = 0.351955, accuracy/threshold_0.500000_mean = 0.731844, auc = 0.721949, global_step = 400, labels/actual_label_mean = 0.351955, labels/prediction_mean = 0.322155, loss = 0.585682, precision/positive_threshold_0.500000_mean = 0.702703, recall/positive_threshold_0.500000_mean = 0.412698\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.73184359,\n",
       " 'accuracy/baseline_label_mean': 0.35195529,\n",
       " 'accuracy/threshold_0.500000_mean': 0.73184359,\n",
       " 'auc': 0.72194856,\n",
       " 'global_step': 400,\n",
       " 'labels/actual_label_mean': 0.35195529,\n",
       " 'labels/prediction_mean': 0.32215518,\n",
       " 'loss': 0.58568209,\n",
       " 'precision/positive_threshold_0.500000_mean': 0.7027027,\n",
       " 'recall/positive_threshold_0.500000_mean': 0.41269842}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "tf_clf_dnn = skflow.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[20, 40, 20], \n",
    "    n_classes=2, \n",
    "    model_dir=\"./titanic_DNN_model\")\n",
    "tf_clf_dnn.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    steps=200)\n",
    "tf_clf_dnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:374: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:247: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  equality = a == b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:374: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    }
   ],
   "source": [
    "prediction = tf_clf_dnn.predict(X_test)\n",
    "#passenger_set[passenger_set.survived != prediction]\n",
    "predictions = list(tf_clf_dnn.predict(X_test))\n",
    "#X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
